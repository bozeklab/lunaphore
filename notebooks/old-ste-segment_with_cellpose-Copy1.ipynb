{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18050be7-fa86-4f95-a1f4-647c16e1df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%reload_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import cv2 as cv\n",
    "from cellpose import models, io, plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from utils import list_subdir_filter as lsd#, slide_cycle_dot as scd\n",
    "from metadata import metadata\n",
    "\n",
    "md = metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd660bf-3ae2-4f00-af88-a0d248ef9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files =  lsd(md.folders['bg_removed'], True, '\\.npy')\n",
    "out_dir = os.path.join(md.folders['segmented'], 'cellpose')\n",
    "Path(out_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model = models.Cellpose(gpu=True, model_type='nuclei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964a6b93-8d41-46b2-924a-612b19f9b0bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch'"
     ]
    }
   ],
   "source": [
    "import pytorch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f06d21-38ae-43c8-bd22-28a6446619a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/projects/ag-bozek/lunaphore/data/interim/bg_removed/A40.2294_bg_removed_uint8.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_files[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bba7615-5062-473c-9f36-32971c151139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                 | 0/1 [01:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 31.75 GiB total capacity; 2.62 GiB already allocated; 203.19 MiB free; 2.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:9\u001b[0m\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/models.py:164\u001b[0m, in \u001b[0;36mCellpose.eval\u001b[0;34m(self, x, batch_size, channels, channel_axis, invert, normalize, diameter, do_3D, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    163\u001b[0m models_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~~~ ESTIMATING CELL DIAMETER(S) ~~~\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m diams, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m diameter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    168\u001b[0m models_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimated cell diameter(s) in \u001b[39m\u001b[38;5;132;01m%0.2f\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    169\u001b[0m                    (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tic))\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/models.py:678\u001b[0m, in \u001b[0;36mSizeModel.eval\u001b[0;34m(self, x, channels, channel_axis, normalize, invert, augment, tile, batch_size, progress)\u001b[0m\n\u001b[1;32m    674\u001b[0m diam_style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size_estimation(np\u001b[38;5;241m.\u001b[39marray(styles))\n\u001b[1;32m    675\u001b[0m diam_style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiam_mean \u001b[38;5;28;01mif\u001b[39;00m (diam_style \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    676\u001b[0m                                 np\u001b[38;5;241m.\u001b[39misnan(diam_style)) \u001b[38;5;28;01melse\u001b[39;00m diam_style\n\u001b[0;32m--> 678\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiam_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiam_style\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiam_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    685\u001b[0m diam \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdiameters(masks)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    686\u001b[0m diam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiam_mean \u001b[38;5;28;01mif\u001b[39;00m (diam \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(diam)) \u001b[38;5;28;01melse\u001b[39;00m diam\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/models.py:410\u001b[0m, in \u001b[0;36mCellposeModel.eval\u001b[0;34m(self, x, batch_size, resample, channels, channel_axis, z_axis, normalize, invert, rescale, diameter, flow_threshold, cellprob_threshold, do_3D, anisotropy, stitch_threshold, min_size, niter, augment, tile, tile_overlap, bsize, interp, compute_masks, progress)\u001b[0m\n\u001b[1;32m    407\u001b[0m     diameter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiam_labels\n\u001b[1;32m    408\u001b[0m     rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiam_mean \u001b[38;5;241m/\u001b[39m diameter\n\u001b[0;32m--> 410\u001b[0m masks, styles, dP, cellprob, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_cp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_overlap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcellprob_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcellprob_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_3D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manisotropy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manisotropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mniter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstitch_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstitch_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m flows \u001b[38;5;241m=\u001b[39m [plot\u001b[38;5;241m.\u001b[39mdx_to_circ(dP), dP, cellprob, p]\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m masks, flows, styles\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/models.py:517\u001b[0m, in \u001b[0;36mCellposeModel._run_cp\u001b[0;34m(self, x, compute_masks, normalize, invert, niter, rescale, resample, augment, tile, tile_overlap, cellprob_threshold, bsize, flow_threshold, min_size, interp, anisotropy, do_3D, stitch_threshold)\u001b[0m\n\u001b[1;32m    514\u001b[0m iterator \u001b[38;5;241m=\u001b[39m trange(nimg, file\u001b[38;5;241m=\u001b[39mtqdm_out,\n\u001b[1;32m    515\u001b[0m                   mininterval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m nimg \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nimg)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m--> 517\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_and_compute_masks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdP\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcellprob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mniter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcellprob_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcellprob_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflow_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstitch_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# turn off for 3D stitching\u001b[39;49;00m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m     masks\u001b[38;5;241m.\u001b[39mappend(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    529\u001b[0m     p\u001b[38;5;241m.\u001b[39mappend(outputs[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/dynamics.py:779\u001b[0m, in \u001b[0;36mresize_and_compute_masks\u001b[0;34m(dP, cellprob, p, niter, cellprob_threshold, flow_threshold, interp, do_3D, min_size, resize, device)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresize_and_compute_masks\u001b[39m(dP, cellprob, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, niter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, cellprob_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    759\u001b[0m                              flow_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, interp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, do_3D\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, min_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m    760\u001b[0m                              resize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute masks using dynamics from dP and cellprob, and resizes masks if resize is not None.\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m        tuple: A tuple containing the computed masks and the final pixel locations.\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m     mask, p \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcellprob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mniter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcellprob_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcellprob_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mflow_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_3D\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_3D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    785\u001b[0m         mask \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mresize_image(mask, resize[\u001b[38;5;241m0\u001b[39m], resize[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    786\u001b[0m                                        interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_NEAREST)\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/dynamics.py:836\u001b[0m, in \u001b[0;36mcompute_masks\u001b[0;34m(dP, cellprob, p, niter, cellprob_threshold, flow_threshold, interp, do_3D, min_size, device)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m do_3D:\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m flow_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m flow_threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    835\u001b[0m         \u001b[38;5;66;03m# make sure labels are unique at output of get_masks\u001b[39;00m\n\u001b[0;32m--> 836\u001b[0m         mask \u001b[38;5;241m=\u001b[39m \u001b[43mremove_bad_flow_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m16\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     recast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/dynamics.py:657\u001b[0m, in \u001b[0;36mremove_bad_flow_masks\u001b[0;34m(masks, flows, threshold, device)\u001b[0m\n\u001b[1;32m    654\u001b[0m         dynamics_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mturn off QC step with flow_threshold=0 if too slow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    655\u001b[0m         device0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m merrors, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m badi \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m (merrors \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    659\u001b[0m masks[np\u001b[38;5;241m.\u001b[39misin(masks, badi)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/metrics.py:256\u001b[0m, in \u001b[0;36mflow_error\u001b[0;34m(maski, dP_net, device)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# flows predicted from estimated masks\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m dP_masks \u001b[38;5;241m=\u001b[39m \u001b[43mdynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasks_to_flows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaski\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# difference between predicted flows vs mask flows\u001b[39;00m\n\u001b[1;32m    258\u001b[0m flow_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(maski\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/dynamics.py:358\u001b[0m, in \u001b[0;36mmasks_to_flows\u001b[0;34m(masks, device, niter)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mu\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m masks\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 358\u001b[0m     mu, mu_c \u001b[38;5;241m=\u001b[39m \u001b[43mmasks_to_flows_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mniter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mu\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/dynamics.py:182\u001b[0m, in \u001b[0;36mmasks_to_flows_gpu\u001b[0;34m(masks, device, niter)\u001b[0m\n\u001b[1;32m    180\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ext\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;28;01mif\u001b[39;00m niter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m niter\n\u001b[1;32m    181\u001b[0m shape \u001b[38;5;241m=\u001b[39m masks_padded\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 182\u001b[0m mu \u001b[38;5;241m=\u001b[39m \u001b[43m_extend_centers_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeds_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misneighbor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# new normalization\u001b[39;00m\n\u001b[1;32m    186\u001b[0m mu \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1e-60\u001b[39m \u001b[38;5;241m+\u001b[39m (mu\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m/projects/ag-bozek/stefano/pytorch_env/lib/python3.9/site-packages/cellpose/dynamics.py:80\u001b[0m, in \u001b[0;36m_extend_centers_gpu\u001b[0;34m(neighbors, meds, isneighbor, shape, n_iter, device)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[1;32m     79\u001b[0m     T[meds[:, \u001b[38;5;241m0\u001b[39m], meds[:, \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 80\u001b[0m     Tneigh \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     81\u001b[0m     Tneigh \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m isneighbor\n\u001b[1;32m     82\u001b[0m     T[\u001b[38;5;28mtuple\u001b[39m(neighbors[:, \u001b[38;5;241m0\u001b[39m])] \u001b[38;5;241m=\u001b[39m Tneigh\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 31.75 GiB total capacity; 2.62 GiB already allocated; 203.19 MiB free; 2.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for img_file in tqdm(img_files[2:3]):\n",
    "    tissue_id =re.sub('.*A40\\.([0-9]{4}).*$', '\\\\1', img_file)\n",
    "    img = np.load(img_file)[0]\n",
    "    max_size = np.shape(img)[0]\n",
    "    width = 3000\n",
    "    for i in range((max_size // width) + 1):\n",
    "        print(i)\n",
    "        min_row, max_row = max(0, i * width - 100), min(max_size, (i+1) * width + 100)\n",
    "        masks, flows, styles, diams = model.eval(img[min_row:max_row], diameter=None, channels=[0,0])\n",
    "        pickle_dict = {'masks':masks, 'flows':flows, 'styles':styles, 'diams':diams}\n",
    "        np.save(f'T3_A40_{tissue_id}_dapi1_masks_{i:02}.npy', masks)\n",
    "        with open(os.path.join(out_dir, f'T3_A40_{tissue_id}_dapi1_{i:02}.pkl'), 'wb') as handle:\n",
    "            pickle.dump(pickle_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# it was 42 minutes, let's see now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb8f7dc8-6add-41e3-97d5-1d84c917b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 26.6 s, total: 1min 39s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "masks, flows, styles, diams = model.eval(ii[:, :3300], diameter=None, channels=[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918544a6-25f4-4b48-9138-26dbfdb6e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open(os.path.join(out_dir, f'test.pkl'), 'wb') as handle:\n",
    "    pickle.dump(masks, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "642beae5-53fe-4884-8448-75298cfbc68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.7 ms, sys: 42.4 ms, total: 45.1 ms\n",
      "Wall time: 298 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save(os.path.join(out_dir, f'test.pkl'), masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c389d3f-1c86-4036-a4cc-10894392b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 668 ms, total: 668 ms\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# masks, flows, styles, diams = model.eval(img[i*3], diameter=None, channels=[0,0])\n",
    "pickle_dict = {'masks':masks, 'flows':flows, 'styles':styles, 'diams':diams}\n",
    "with open(os.path.join(out_dir, f'A.pkl'), 'wb') as handle:\n",
    "    pickle.dump(pickle_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957cd0e-2c4f-49d9-9b07-19219a40d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "12096 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fe0f3-914f-4a59-a753-47ae9c0c0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 12096 / 2\n",
    "measures = []\n",
    "for i in range(2):\n",
    "    measures.append([int(max(unit * i - unit/8, 0)), int(min(unit * (i+1) + unit/8, 12096))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bf5ca-b26d-4af2-b011-fe41f2a4e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_file in tqdm(img_files):\n",
    "    tissue_id =re.sub('.*A40\\.([0-9]{4}).*$', '\\\\1', img_file)\n",
    "    img = np.load(img_file)\n",
    "    for i in range(4):\n",
    "        try:\n",
    "            masks, flows, styles, diams = model.eval(img[i*3], diameter=None, channels=[0,0])\n",
    "            pickle_dict = {'masks':masks}, 'flows':flows, 'styles':styles, 'diams':diams}\n",
    "            with open(os.path.join(out_dir, f'A40_{tissue_id}_dapi{i}.pkl'), 'wb') as handle:\n",
    "                pickle.dump(masks, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        except:\n",
    "            print(f'Error with sample A40.{tissue_id}_dapi{i}')\n",
    "        # for j in range(2):\n",
    "        #     for k in range(2):\n",
    "        #         to_process = img[i, slice(*measures[j]), slice(*measures[k])]\n",
    "        #         masks, flows, styles, diams = model.eval(to_process, diameter=None, channels=[0,0])\n",
    "        #         pickle_dict = {'masks':masks, 'flows':flows, 'styles':styles, 'diams':diams}\n",
    "        #         with open(os.path.join(out_dir, f'slide{slide}_dot{dot}_dapi{i}_tile{j}_{k}.pkl'), 'wb') as handle:\n",
    "        #             pickle.dump(pickle_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b245484-71c0-44cd-b2c7-6b235eeb258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plot.show_segmentation(fig, im1[0], masks, flows[0], channels=[0,0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fc3d4-db92-4072-b6cc-58036328d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flows[0][::10, ::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e7ef7-1d8a-48c1-905f-e2979d0144ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_img[1], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
