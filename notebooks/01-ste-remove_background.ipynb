{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3b254-9f04-4363-99c2-c66979d86bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%reload_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view as sww\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import tifffile as tiff\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from metadata import metadata\n",
    "from utils import list_subdir_filter as lsd, get_id, time_diff, unique\n",
    "\n",
    "global md\n",
    "md = metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021567b4-ecdb-48a1-9247-b23d63446567",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def how_old(path):\n",
    "    age = int((time() - os.path.getmtime(path)) // 3600)\n",
    "    if age < 1:\n",
    "        return '<1h'\n",
    "    if age < 24:\n",
    "        return f'{age}h'\n",
    "    age = int(age // 24)\n",
    "    if age < 365:\n",
    "        return f'{age}d'\n",
    "    return '>1y'\n",
    "    \n",
    "        \n",
    "def export_img_signal_histogram(signal_minus_AF, sample_id, marker_name):\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    p = plt.hist(signal_minus_AF.flatten()[::4], log=True, bins=150, color='green')\n",
    "    plt.title(f'{sample_id} ({marker_name}) post-AF correction')\n",
    "    plt.vlines(x=0, ymin=0.1, ymax=p[0].max()*1.02, color='gold')\n",
    "    plt.xlim(-65535, 65535)\n",
    "    plt.savefig(os.path.join(md.folders['bg_removed'], f'intensity_dist_AF_correction_{sample_id}_{marker_name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def export_img_signal_AF_overlap(rgb_array, sample_id, marker_name):\n",
    "\n",
    "    if np.shape(rgb_array)[0] < np.shape(rgb_array)[-1]:\n",
    "        rgb_array = np.moveaxis(rgb_array, 0, -1)\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(rgb_array)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{sample_id}: AF/{marker_name}')\n",
    "    plt.savefig(os.path.join(md.folders['bg_removed'], f'AF_correction_{sample_id}_{marker_name}.png'), transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def combine_clean_AF_channels(signal_minus_AF, AF, clipping_threshold, scale_factor=8):\n",
    "    \n",
    "    def normalize_clipped(array, clipping_threshold):\n",
    "        return np.clip(array, 0, clipping_threshold)/clipping_threshold\n",
    "    \n",
    "    combined_RGB = [\n",
    "        normalize_clipped(signal_minus_AF[::scale_factor, ::scale_factor], clipping_threshold),\n",
    "        normalize_clipped(AF[::scale_factor, ::scale_factor], clipping_threshold),\n",
    "        normalize_clipped(signal_minus_AF[::scale_factor, ::scale_factor], clipping_threshold)\n",
    "    ]\n",
    "\n",
    "    return combined_RGB\n",
    "\n",
    "\n",
    "\n",
    "def subtract_AF(signal, af, img_id, marker_name, clipping_threshold=20000):\n",
    "\n",
    "    clean = signal.astype('int32') - af\n",
    "    \n",
    "    export_img_signal_histogram(clean, img_id, marker_name)\n",
    "\n",
    "    combined_clean_AF = combine_clean_AF_channels(\n",
    "        clean, \n",
    "        af, \n",
    "        clipping_threshold=clipping_threshold, \n",
    "        scale_factor=8\n",
    "    )\n",
    "\n",
    "    export_img_signal_AF_overlap(combined_clean_AF, img_id, marker_name)\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(md.folders['bg_removed'], f'clean_{marker_name}_{img_id}.npy'),\n",
    "        (np.clip(clean, 0, np.Inf).astype('uint16') >> 8).astype('uint8')\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def do_the_cleaning(img_file):\n",
    "    img_id = get_id(img_file)\n",
    "    print(img_id)\n",
    "\n",
    "    markers = list(md.markers)\n",
    "\n",
    "    existing = sum([os.path.exists(os.path.join(md.folders['bg_removed'], f'clean_{marker}_{img_id}.npy')) for marker in markers])\n",
    "    if existing == 9:\n",
    "        print(f'{img_id} already processed, skipping')\n",
    "        return None\n",
    "    \n",
    "    bg = tiff.imread(img_file, key=1)\n",
    "    \n",
    "    for i in range(3, len(md.markers), 2):\n",
    "        marker = markers[i]\n",
    "        print(marker)\n",
    "        signal = tiff.imread(img_file, key=i)\n",
    "        subtract_AF(signal, bg, img_id, marker_name=marker)\n",
    "\n",
    "    bg = tiff.imread(img_file, key=2)\n",
    "    for i in range(4, len(md.markers), 2):\n",
    "        marker = markers[i]\n",
    "        print(marker)\n",
    "        signal = tiff.imread(img_file, key=i)\n",
    "        subtract_AF(signal, bg, img_id, marker_name=marker)\n",
    "\n",
    "\n",
    "def safe_cleaning(img_file):\n",
    "    img_id = get_id(img_file)\n",
    "    print(img_id)\n",
    "    do_the_cleaning(img_file)\n",
    "\n",
    "    # try:\n",
    "    #     do_the_cleaning(img_file)\n",
    "    # except:\n",
    "    #     print(f'error with {img_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4297e-dd92-4a7d-a8c2-38303a8a08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_files = lsd(md.folders['images'], True, '.tif')\n",
    "\n",
    "for f in all_img_files:\n",
    "    print(get_id(f), how_old(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172c2ba-934d-42f2-a3df-d5d9c6df0b81",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for img_file in tqdm(all_img_files)\n",
    "    safe_cleaning(img_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
